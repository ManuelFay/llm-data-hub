data_mix:
  (): dataset_construction.DataMix
  name: "french_5p"
  shuffle: false
  compute_dataset_stats: true
  keep_separated_datasets_in_dataset_dict: true
  deduplicate_test_set: false
  ngram_path_for_extra_deduplication: null
  datasets:
# Translation datasets
#    - (): dataset_construction.DatasetConfig
#      dataset_path: manu/opus100-en-fr
#      test_split: "test"
#      build_test_set_from_train: false
#      num_train_examples:  1000
#      num_test_examples: 1000
#    - (): dataset_construction.DatasetConfig
#      dataset_path: manu/europarl-en-fr
#      build_test_set_from_train: true
#      num_test_examples: 1000
    - (): dataset_construction.DatasetConfig
      dataset_path: manu/wmt-en-fr
      test_split: "test"
# Speech datasets
    - (): dataset_construction.DatasetConfig
      dataset_path: manu/french_librispeech_text_only
      build_test_set_from_train: true
    - (): dataset_construction.DatasetConfig
      dataset_path: manu/french_podcasts
      build_test_set_from_train: true
      num_test_examples: 100
      filtering_function:
        (): dataset_collection.french.french_transcribed_podcast.PodcastFilter
      preprocessing_function:
        (): dataset_collection.french.french_transcribed_podcast.PodcastMapper
    - (): dataset_construction.DatasetConfig
      dataset_path: manu/french_open_subtitles
      num_test_examples: 100
# Books
#    - (): dataset_construction.DatasetConfig
#      dataset_path: manu/project_gutenberg
#      train_split: fr
#      build_test_set_from_train: true
#      num_train_examples:  1000
#      num_test_examples: 100
      # here we should preprocess
    - (): dataset_construction.DatasetConfig
      dataset_path: manu/ProjectGutenberg_fr
      build_test_set_from_train: true
    - (): dataset_construction.DatasetConfig
      dataset_path: manu/bnf_gallica
      build_test_set_from_train: true
# Dila data
    - (): dataset_construction.DatasetConfig
      dataset_path: manu/dila_legifrance
      build_test_set_from_train: true
    - (): dataset_construction.DatasetConfig
      dataset_path: Nicolas-BZRD/BALO_opendata
      build_test_set_from_train: true
      # needs a preprocessor to have an id_column
# PDF dataset
    - (): dataset_construction.DatasetConfig
      dataset_path: manu/illuin_layout_dataset_text_only
      build_test_set_from_train: true
 # Wiki
    - (): dataset_construction.DatasetConfig
      dataset_path: manu/wikisource_fr
      build_test_set_from_train: true
      train_split: "train[:5%]"
    - (): dataset_construction.DatasetConfig
      dataset_path: wikipedia
      dataset_name: "20220301.fr"
      train_split: "train[:5%]"
      build_test_set_from_train: true
 # Internet dumps
    - (): dataset_construction.DatasetConfig
      dataset_path: 'oscar-corpus/OSCAR-2301'
      dataset_name: fr
      train_split: "train[:5%]"
      build_test_set_from_train: true
      num_test_examples: 10000
      filtering_function:
        (): dataset_collection.french.oscar.OscarFilter


tokenizer: "mistralai/Mistral-7B-v0.1"
