{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BALO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".taz files are generally badly handled by this script, so many folders have to be decompressed by hand with appropriate software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract compressed folders and subfolders recursively\n",
    "def extract_folders_recursively(folder_path):\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            # Check if the file is a ZIP archive\n",
    "            if zipfile.is_zipfile(file_path):\n",
    "                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(root)\n",
    "                os.remove(file_path)  # Optional: Remove the original ZIP file\n",
    "                \n",
    "            elif file_path.endswith('.tar.gz') or file_path.endswith('.tgz') or file_path.endswith('.taz') or file_path.endswith('.tar') :\n",
    "                try :\n",
    "                    with tarfile.open(file_path, 'r:gz') as tar_ref:\n",
    "                        tar_ref.extractall(root)\n",
    "                    os.remove(file_path)  # Optional: Remove the original TAR.GZ file\n",
    "                except : print(f\"Error : {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2016.tar\n",
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2014.tar\n",
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2015.tar\n",
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2011.tar\n",
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2005.tar\n",
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2010.tar\n",
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2006.tar\n",
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2012.tar\n",
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2013.tar\n",
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2007.tar\n",
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2009.tar\n",
      "Error : /Users/nboizard/Downloads/dataset_collection/french/dila_opendata/data/echanges.dila.gouv.fr/OPENDATA/BALO/FluxHistorique/old/BALO_2008.tar\n"
     ]
    }
   ],
   "source": [
    "extract_folders_recursively(r\"/Users/nboizard/Downloads/dataset_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create pandas dataset with all text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             file_name                                               text  \\\n",
      "0  202307282303438.txt   BANQUE POPULAIRE AQUITAINE CENTRE ATLANTIQUE ...   \n",
      "1  202306282303013.txt   CAISSE DE CREDIT MUNICIPAL DE NICE Etablissem...   \n",
      "2  202304172300881.txt   CGG  Société anonyme au capital de  7 123  81...   \n",
      "3  202305122301586.txt   Biophytis Société anonyme Au capital de  3.17...   \n",
      "4  202305172301636.txt   STREAMWIDE Société  a nonyme  a u capital de ...   \n",
      "\n",
      "   year  number_words  \n",
      "0  2023           287  \n",
      "1  2023            83  \n",
      "2  2023          2538  \n",
      "3  2023          3467  \n",
      "4  2023          9509  \n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "root_folder = r\"/Users/nboizard/Downloads/dataset_collection\"\n",
    "\n",
    "def count_words(text):\n",
    "    words = text.split()\n",
    "    return len(words)\n",
    "\n",
    "for parent_folder, subfolders, files in os.walk(root_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(parent_folder, file)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                data.append((file, text, file[0:4], count_words(text)))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"file_name\", \"text\", \"year\", \"number_words\"])\n",
    "\n",
    "df.to_csv(\"balo.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"balo.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r\"'\\s+\", \"'\", text)\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file_name', 'text', 'year', 'number_words'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 13/13 [00:03<00:00,  3.80ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 13/13 [00:03<00:00,  3.45ba/s]3s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 2/2 [04:44<00:00, 142.46s/it]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 2/2 [00:00<00:00,  3.59it/s]\n",
      "Downloading metadata: 100%|██████████| 452/452 [00:00<00:00, 736kB/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.remove_columns(\"__index_level_0__\")\n",
    "dataset.push_to_hub(\"Nicolas-BZRD/BALO_fr_gouv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scraped",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
